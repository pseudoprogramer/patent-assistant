import streamlit as st
import os
import google.generativeai as genai
from google.api_core import exceptions
import time

# --- 1. ì• í”Œë¦¬ì¼€ì´ì…˜ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(
    page_title="í´ë¼ìš°ë“œ íŠ¹í—ˆ ë¶„ì„ Q&A (Gemini 2.5)",
    page_icon="âœ¨",
    layout="wide"
)

st.title("âœ¨ AI íŠ¹í—ˆ ë¶„ì„ Q&A (Google Cloud ê¸°ë°˜)")
st.markdown("Google ì„œë²„ì— ì—…ë¡œë“œëœ ê°œì¸ íŠ¹í—ˆ ìë£Œì‹¤ì„ ê¸°ë°˜ìœ¼ë¡œ, ìµœì‹  Gemini ëª¨ë¸ì´ ì§ì ‘ ê²€ìƒ‰í•˜ê³  ë‹µë³€í•©ë‹ˆë‹¤.")

# --- 2. ì‚¬ì´ë“œë°” - ì„¤ì • ---
with st.sidebar:
    st.header("âœ¨ AI ì„¤ì •")
    # Gemini API í‚¤ëŠ” Streamlitì˜ ë¹„ë°€ ê´€ë¦¬ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.
    gemini_api_key = st.text_input("Gemini API Key", type="password", help="[Google AI Studio](https://aistudio.google.com/app/apikey)ì—ì„œ ë°œê¸‰ë°›ìœ¼ì„¸ìš”.")
    
    st.markdown("---")
    st.header("ğŸ¤– ëª¨ë¸ ì„ íƒ")
    # [ìˆ˜ì •] ìµœì‹  2.5 ëª¨ë¸ì„ ì‚¬ìš©í•˜ë„ë¡ ì˜µì…˜ ë³€ê²½
    selected_model = st.radio(
        "ë‹µë³€ ìƒì„± ëª¨ë¸ ì„ íƒ:",
        ("gemini-2.5-pro", "gemini-2.5-flash"),
        captions=["ìµœê³  í’ˆì§ˆ (2.5 Pro)", "ìµœì‹ /ê· í˜• (2.5 Flash)"],
        horizontal=True,
        index=0 # ê¸°ë³¸ê°’ìœ¼ë¡œ 2.5 Pro ì„ íƒ
    )

    if st.button("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()

# --- 3. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ---
@st.cache_data(ttl=3600) # 1ì‹œê°„ ë™ì•ˆ ìºì‹œ ìœ ì§€
def get_uploaded_files_list(_api_key):
    """Google File APIì— ì—…ë¡œë“œëœ ëª¨ë“  íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    print("Google ì„œë²„ì—ì„œ íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
    try:
        # í•¨ìˆ˜ ë‚´ì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•˜ì—¬ ìºì‹œê°€ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ë„ë¡ í•¨
        genai.configure(api_key=_api_key)
        # ì²˜ë¦¬ ì¤‘(PROCESSING)ì¸ íŒŒì¼ì„ ì œì™¸í•˜ê³ , ì‚¬ìš© ê°€ëŠ¥í•œ(ACTIVE) íŒŒì¼ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        files = [f for f in genai.list_files() if f.state.name == "ACTIVE"]
        return files
    except Exception as e:
        st.error(f"Google ì„œë²„ì—ì„œ íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        return []

# --- 4. ë©”ì¸ Q&A ë¡œì§ ---
if not gemini_api_key:
    st.info("ì‚¬ì´ë“œë°”ì— Gemini API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
else:
    try:
        # ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        uploaded_files = get_uploaded_files_list(gemini_api_key)

        if not uploaded_files:
            st.warning("Google ì„œë²„ì— ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            # [ìˆ˜ì •] ëª¨ë¸ì„ ë¨¼ì € ê°„ë‹¨í•˜ê²Œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
            model = genai.GenerativeModel(model_name=selected_model)

            # ì±„íŒ… UI ì´ˆê¸°í™”
            if "messages" not in st.session_state:
                st.session_state.messages = []

            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

            if prompt := st.chat_input("ì—…ë¡œë“œëœ íŠ¹í—ˆì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”..."):
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)

                with st.chat_message("assistant"):
                    with st.spinner(f"Gemini {selected_model} ëª¨ë¸ì´ ë‹¹ì‹ ì˜ íŠ¹í—ˆ ìë£Œì‹¤ì„ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                        try:
                            # [ìˆ˜ì •] ëª¨ë¸ì— ì§ˆë¬¸(prompt)ê³¼ íŒŒì¼ ëª©ë¡(uploaded_files)ì„ í•¨ê»˜ ì „ë‹¬í•©ë‹ˆë‹¤.
                            # ì´ê²ƒì´ ë°”ë¡œ groundingì„ ìˆ˜í–‰í•˜ëŠ” ê°€ì¥ ìµœì‹  ë°©ì‹ì…ë‹ˆë‹¤.
                            response = model.generate_content([prompt] + uploaded_files)
                            
                            response_text = response.text
                            st.markdown(response_text)
                            st.session_state.messages.append({"role": "assistant", "content": response_text})

                            # [í•µì‹¬] ë‹µë³€ì˜ ê·¼ê±°ê°€ ëœ ì¶œì²˜ í‘œì‹œ (Attributed Question Answering)
                            try:
                                # ì‘ë‹µ ê°ì²´ì—ì„œ citation_metadataë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
                                citations = response.candidates[0].citation_metadata.citation_sources
                                if citations:
                                    with st.expander("ë‹µë³€ ê·¼ê±° ë³´ê¸° (ì°¸ê³  íŠ¹í—ˆ)"):
                                        for citation in citations:
                                            # File APIì˜ ì‘ë‹µì—ì„œ íŒŒì¼ ì´ë¦„ì„ ì°¾ìœ¼ë ¤ê³  ì‹œë„
                                            file_name = "ì¶œì²˜ íŒŒì¼ ì •ë³´ ì—†ìŒ"
                                            for f in uploaded_files:
                                                if citation.uri in f.uri:
                                                    file_name = f.display_name
                                                    break
                                            st.write(f"ğŸ“„ **{file_name}**")
                            except (AttributeError, IndexError, TypeError):
                                # citation_metadataê°€ ì—†ëŠ” ê²½ìš° ë¬´ì‹œ
                                pass

                        except exceptions.ResourceExhausted as e:
                            st.error(f"ë¬´ë£Œ ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ ì´ˆê³¼í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
                        except Exception as e:
                            st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                            
    except Exception as e:
        st.error(f"ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
